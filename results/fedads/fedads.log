[2023-10-19 14:23:19,383][INFO] vFL config:
[2023-10-19 14:23:19,383][INFO] [dataset]
[2023-10-19 14:23:19,383][INFO]     name = fedads
[2023-10-19 14:23:19,384][INFO]     guestcols = l_i_fea_1,l_i_fea_2,l_i_fea_4,l_i_fea_5,l_u_fea_6,l_i_fea_3,l_i_fea_6,l_i_fea_7,l_i_fea_8,l_i_fea_9,l_i_fea_10,l_u_fea_2,l_u_fea_3,l_u_fea_4,l_u_fea_5
[2023-10-19 14:23:19,384][INFO]     hostcols = l_u_fea_1,f_u_fea_1,f_u_fea_2,f_uc_fea_1,f_uc_fea_2,f_c
[2023-10-19 14:23:19,384][INFO]     guestdensenum = 5
[2023-10-19 14:23:19,384][INFO]     guestsparsenum = 10
[2023-10-19 14:23:19,384][INFO]     hostdensenum = 1
[2023-10-19 14:23:19,384][INFO]     hostsparsenum = 5
[2023-10-19 14:23:19,384][INFO]     embeddingsize = 4
[2023-10-19 14:23:19,384][INFO]     bottomfcdim = 256,64
[2023-10-19 14:23:19,384][INFO]     embeddingdim = 64
[2023-10-19 14:23:19,384][INFO]     topfcdim = 1
[2023-10-19 14:23:19,385][INFO] [training]
[2023-10-19 14:23:19,385][INFO]     epoch = 5
[2023-10-19 14:23:19,385][INFO]     learningrate = 0.05
[2023-10-19 14:23:19,385][INFO]     batchsize = 1024
[2023-10-19 14:23:19,385][INFO]     device = cuda
[2023-10-19 14:23:19,385][INFO]     usemaloptimizer = 0
[2023-10-19 14:23:19,385][INFO]     printinterval = 5
[2023-10-19 14:23:19,385][INFO] [privacy]
[2023-10-19 14:23:19,385][INFO]     normattack = 1
[2023-10-19 14:23:19,385][INFO]     embattack = 1
[2023-10-19 14:23:19,385][INFO]     modelcompletion = 0
[2023-10-19 14:23:19,386][INFO]     mcnlabeled = 200
[2023-10-19 14:23:19,386][INFO]     mcbatch = 16
[2023-10-19 14:23:19,386][INFO]     mclr = 1e-3
[2023-10-19 14:23:19,386][INFO]     mcepochs = 5
[2023-10-19 14:23:19,386][INFO]     mciter = 1024
[2023-10-19 14:23:19,386][INFO]     mcalpha = 0.75
[2023-10-19 14:23:19,386][INFO]     mclambdau = 50
[2023-10-19 14:23:19,386][INFO]     mct = 0.8
[2023-10-19 14:23:19,386][INFO]     mcemadecay = 0.999
[2023-10-19 14:23:19,386][INFO]     dcorloss = 0
[2023-10-19 14:23:19,387][INFO]     dcorcoef = 0.01
[2023-10-19 14:23:19,387][INFO]     labelconfusion = 0
[2023-10-19 14:23:19,387][INFO] >>> Prepare for vFL training...
[2023-10-19 14:23:19,467][INFO] Note: NumExpr detected 16 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2023-10-19 14:23:19,467][INFO] NumExpr defaulting to 8 threads.
[2023-10-19 14:23:22,555][INFO] train set: 2598552
[2023-10-19 14:23:25,267][INFO] test set: 2432490
[2023-10-19 14:23:25,405][INFO] host_bottom_model:
HostBottomModel(
  (embed_part): Embed(
    (embed_layers): ModuleDict(
      (embed_0): Embedding(5, 4)
      (embed_1): Embedding(5, 4)
      (embed_2): Embedding(5, 4)
      (embed_3): Embedding(5, 4)
      (embed_4): Embedding(3, 4)
    )
  )
  (deep_part): Deep(
    (dnn): ModuleList(
      (0): Linear(in_features=21, out_features=256, bias=True)
      (1): Linear(in_features=256, out_features=64, bias=True)
      (2): Linear(in_features=64, out_features=32, bias=True)
    )
    (dropout): Dropout(p=0.0, inplace=False)
    (relu): ReLU()
  )
)
[2023-10-19 14:23:25,406][INFO] guest_bottom_model:
GuestBottomModel(
  (wide_embed): Embed(
    (embed_layers): ModuleDict(
      (embed_0): Embedding(5, 4)
      (embed_1): Embedding(9, 4)
      (embed_2): Embedding(10, 4)
      (embed_3): Embedding(10, 4)
      (embed_4): Embedding(10, 4)
      (embed_5): Embedding(10, 4)
      (embed_6): Embedding(3, 4)
      (embed_7): Embedding(4, 4)
      (embed_8): Embedding(5, 4)
      (embed_9): Embedding(12, 4)
    )
  )
  (deep_embed): Embed(
    (embed_layers): ModuleDict(
      (embed_0): Embedding(5, 4)
      (embed_1): Embedding(9, 4)
      (embed_2): Embedding(10, 4)
      (embed_3): Embedding(10, 4)
      (embed_4): Embedding(10, 4)
      (embed_5): Embedding(10, 4)
      (embed_6): Embedding(3, 4)
      (embed_7): Embedding(4, 4)
      (embed_8): Embedding(5, 4)
      (embed_9): Embedding(12, 4)
    )
  )
  (wide_sparse_part): Wide(
    (fc): Linear(in_features=40, out_features=1, bias=True)
  )
  (wide_dense_part): Wide(
    (fc): Linear(in_features=5, out_features=1, bias=True)
  )
  (deep_part): Deep(
    (dnn): ModuleList(
      (0): Linear(in_features=45, out_features=256, bias=True)
      (1): Linear(in_features=256, out_features=64, bias=True)
      (2): Linear(in_features=64, out_features=32, bias=True)
    )
    (dropout): Dropout(p=0.0, inplace=False)
    (relu): ReLU()
  )
)
[2023-10-19 14:23:25,407][INFO] guest_top_model:
GuestTopModel(
  (deep_part): Deep(
    (dnn): ModuleList(
      (0): Linear(in_features=64, out_features=1, bias=True)
    )
    (dropout): Dropout(p=0.0, inplace=False)
    (relu): ReLU()
  )
  (relu): ReLU()
)
[2023-10-19 14:23:25,408][INFO] 
[2023-10-19 14:23:25,408][INFO] >>> vFL training and evaluating starts...
[2023-10-19 14:23:25,408][INFO] 
[2023-10-19 14:23:25,408][INFO] Epoch [1 | 5]:   BatchSize = 1024	hostLR = 0.0500000  guestLR = 0.0500000  topLR = 0.0500000
[2023-10-19 14:23:28,040][INFO] Epoch [1]: [130048/2598552] (5.00%)	Loss: 0.0156	AUC: 0.7016(0.5180)
[2023-10-19 14:23:28,040][INFO] 	norm attack AUC: 1.0000(0.9868)
[2023-10-19 14:23:28,040][INFO] 	emb attack AUC: 0.7079(0.6013)
[2023-10-19 14:23:30,515][INFO] Epoch [1]: [260096/2598552] (10.01%)	Loss: 0.0448	AUC: 0.3627(0.5078)
[2023-10-19 14:23:30,516][INFO] 	norm attack AUC: 1.0000(0.9914)
[2023-10-19 14:23:30,516][INFO] 	emb attack AUC: 0.5357(0.5998)
[2023-10-19 14:23:33,035][INFO] Epoch [1]: [390144/2598552] (15.01%)	Loss: 0.0226	AUC: 0.2893(0.5087)
[2023-10-19 14:23:33,036][INFO] 	norm attack AUC: 1.0000(0.9943)
[2023-10-19 14:23:33,036][INFO] 	emb attack AUC: 0.5723(0.5986)
[2023-10-19 14:23:35,676][INFO] Epoch [1]: [520192/2598552] (20.02%)	Loss: 0.0583	AUC: 0.4665(0.5119)
[2023-10-19 14:23:35,677][INFO] 	norm attack AUC: 1.0000(0.9947)
[2023-10-19 14:23:35,677][INFO] 	emb attack AUC: 0.5182(0.6011)
[2023-10-19 14:23:38,164][INFO] Epoch [1]: [650240/2598552] (25.02%)	Loss: 0.0208	AUC: 0.6797(0.5106)
[2023-10-19 14:23:38,164][INFO] 	norm attack AUC: 1.0000(0.9950)
[2023-10-19 14:23:38,164][INFO] 	emb attack AUC: 0.7728(0.6019)
[2023-10-19 14:23:42,122][INFO] Epoch [1]: [780288/2598552] (30.03%)	Loss: 0.0568	AUC: 0.5020(0.5094)
[2023-10-19 14:23:42,123][INFO] 	norm attack AUC: 1.0000(0.9958)
[2023-10-19 14:23:42,123][INFO] 	emb attack AUC: 0.5141(0.6024)
[2023-10-19 14:23:47,449][INFO] Epoch [1]: [910336/2598552] (35.03%)	Loss: 0.0466	AUC: 0.5589(0.5088)
[2023-10-19 14:23:47,450][INFO] 	norm attack AUC: 1.0000(0.9964)
[2023-10-19 14:23:47,450][INFO] 	emb attack AUC: 0.5917(0.6032)
[2023-10-19 14:23:52,584][INFO] Epoch [1]: [1040384/2598552] (40.04%)	Loss: 0.0300	AUC: 0.6828(0.5144)
[2023-10-19 14:23:52,584][INFO] 	norm attack AUC: 1.0000(0.9969)
[2023-10-19 14:23:52,584][INFO] 	emb attack AUC: 0.5576(0.6032)
[2023-10-19 14:23:57,787][INFO] Epoch [1]: [1169408/2598552] (45.00%)	Loss: 0.0463	AUC: 0.5359(0.5170)
[2023-10-19 14:23:57,787][INFO] 	norm attack AUC: 1.0000(0.9972)
[2023-10-19 14:23:57,788][INFO] 	emb attack AUC: 0.6442(0.6031)
[2023-10-19 14:24:03,559][INFO] Epoch [1]: [1299456/2598552] (50.01%)	Loss: 0.0512	AUC: 0.5329(0.5178)
[2023-10-19 14:24:03,560][INFO] 	norm attack AUC: 1.0000(0.9975)
[2023-10-19 14:24:03,560][INFO] 	emb attack AUC: 0.5981(0.6033)
[2023-10-19 14:24:09,407][INFO] Epoch [1]: [1429504/2598552] (55.01%)	Loss: 0.0161	AUC: 0.5788(0.5189)
[2023-10-19 14:24:09,407][INFO] 	norm attack AUC: 1.0000(0.9977)
[2023-10-19 14:24:09,407][INFO] 	emb attack AUC: 0.6791(0.6049)
[2023-10-19 14:24:15,232][INFO] Epoch [1]: [1559552/2598552] (60.02%)	Loss: 0.0309	AUC: 0.5182(0.5199)
[2023-10-19 14:24:15,232][INFO] 	norm attack AUC: 1.0000(0.9979)
[2023-10-19 14:24:15,232][INFO] 	emb attack AUC: 0.6133(0.6045)
[2023-10-19 14:24:21,098][INFO] Epoch [1]: [1689600/2598552] (65.02%)	Loss: 0.0466	AUC: 0.5128(0.5221)
[2023-10-19 14:24:21,098][INFO] 	norm attack AUC: 1.0000(0.9981)
[2023-10-19 14:24:21,098][INFO] 	emb attack AUC: 0.5784(0.6042)
[2023-10-19 14:24:26,864][INFO] Epoch [1]: [1819648/2598552] (70.03%)	Loss: 0.0299	AUC: 0.5700(0.5244)
[2023-10-19 14:24:26,865][INFO] 	norm attack AUC: 1.0000(0.9979)
[2023-10-19 14:24:26,865][INFO] 	emb attack AUC: 0.5095(0.6046)
[2023-10-19 14:24:32,736][INFO] Epoch [1]: [1949696/2598552] (75.03%)	Loss: 0.0355	AUC: 0.6467(0.5266)
[2023-10-19 14:24:32,737][INFO] 	norm attack AUC: 1.0000(0.9981)
[2023-10-19 14:24:32,737][INFO] 	emb attack AUC: 0.5625(0.6052)
[2023-10-19 14:24:38,515][INFO] Epoch [1]: [2079744/2598552] (80.03%)	Loss: 0.0558	AUC: 0.6042(0.5282)
[2023-10-19 14:24:38,515][INFO] 	norm attack AUC: 1.0000(0.9982)
[2023-10-19 14:24:38,516][INFO] 	emb attack AUC: 0.5120(0.6050)
[2023-10-19 14:24:44,394][INFO] Epoch [1]: [2209792/2598552] (85.04%)	Loss: 0.0612	AUC: 0.5447(0.5294)
[2023-10-19 14:24:44,394][INFO] 	norm attack AUC: 1.0000(0.9983)
[2023-10-19 14:24:44,395][INFO] 	emb attack AUC: 0.5131(0.6051)
[2023-10-19 14:24:50,223][INFO] Epoch [1]: [2338816/2598552] (90.00%)	Loss: 0.0403	AUC: 0.6206(0.5313)
[2023-10-19 14:24:50,223][INFO] 	norm attack AUC: 1.0000(0.9984)
[2023-10-19 14:24:50,224][INFO] 	emb attack AUC: 0.5015(0.6055)
[2023-10-19 14:24:56,054][INFO] Epoch [1]: [2468864/2598552] (95.01%)	Loss: 0.0306	AUC: 0.5965(0.5332)
[2023-10-19 14:24:56,055][INFO] 	norm attack AUC: 1.0000(0.9985)
[2023-10-19 14:24:56,055][INFO] 	emb attack AUC: 0.7203(0.6059)
[2023-10-19 14:25:02,131][INFO] Epoch [1]: [2598552/2598552] (100.00%)	Loss: 0.0538	AUC: 0.4445(0.5344)
[2023-10-19 14:25:02,132][INFO] 	norm attack AUC: 1.0000(0.9986)
[2023-10-19 14:25:02,132][INFO] 	emb attack AUC: 0.5301(0.6059)
[2023-10-19 14:25:02,133][INFO] 
[2023-10-19 14:25:02,133][INFO] Evaluate model on train set:
[2023-10-19 14:25:14,189][INFO] 	processing data 20%
[2023-10-19 14:25:25,761][INFO] 	processing data 40%
[2023-10-19 14:25:37,882][INFO] 	processing data 60%
[2023-10-19 14:25:44,377][INFO] 	processing data 80%
[2023-10-19 14:25:49,662][INFO] 	processing data 100%
[2023-10-19 14:25:52,679][INFO] Loss: 0.03625	AUC: 0.5615	Accuracy: 0.9941
[2023-10-19 14:25:52,680][INFO] precision: 0.0066	recall: 0.7438	f1: 0.0066
[2023-10-19 14:25:52,681][INFO] 
[2023-10-19 14:25:52,681][INFO] Evaluate model on test set:
[2023-10-19 14:25:57,053][INFO] 	processing data 20%
[2023-10-19 14:26:01,378][INFO] 	processing data 40%
[2023-10-19 14:26:05,781][INFO] 	processing data 60%
[2023-10-19 14:26:10,377][INFO] 	processing data 80%
[2023-10-19 14:26:15,204][INFO] 	processing data 100%
[2023-10-19 14:26:18,256][INFO] Loss: 0.03858	AUC: 0.5459	Accuracy: 0.9936
[2023-10-19 14:26:18,257][INFO] precision: 0.0069	recall: 0.7368	f1: 0.0068
[2023-10-19 14:26:18,258][INFO] 
[2023-10-19 14:26:18,258][INFO] Epoch [2 | 5]:   BatchSize = 1024	hostLR = 0.0500000  guestLR = 0.0500000  topLR = 0.0500000
[2023-10-19 14:26:20,830][INFO] Epoch [2]: [130048/2598552] (5.00%)	Loss: 0.0474	AUC: 0.3899(0.5367)
[2023-10-19 14:26:20,830][INFO] 	norm attack AUC: 1.0000(0.9961)
[2023-10-19 14:26:20,830][INFO] 	emb attack AUC: 0.5417(0.6055)
[2023-10-19 14:26:23,228][INFO] Epoch [2]: [260096/2598552] (10.01%)	Loss: 0.0508	AUC: 0.5459(0.5547)
[2023-10-19 14:26:23,228][INFO] 	norm attack AUC: 1.0000(0.9941)
[2023-10-19 14:26:23,228][INFO] 	emb attack AUC: 0.5229(0.6091)
[2023-10-19 14:26:25,756][INFO] Epoch [2]: [390144/2598552] (15.01%)	Loss: 0.0305	AUC: 0.5994(0.5514)
[2023-10-19 14:26:25,756][INFO] 	norm attack AUC: 1.0000(0.9948)
[2023-10-19 14:26:25,757][INFO] 	emb attack AUC: 0.5590(0.6084)
[2023-10-19 14:26:28,755][INFO] Epoch [2]: [520192/2598552] (20.02%)	Loss: 0.0509	AUC: 0.5495(0.5517)
[2023-10-19 14:26:28,755][INFO] 	norm attack AUC: 1.0000(0.9951)
[2023-10-19 14:26:28,755][INFO] 	emb attack AUC: 0.5563(0.6063)
[2023-10-19 14:26:31,791][INFO] Epoch [2]: [650240/2598552] (25.02%)	Loss: 0.0213	AUC: 0.4548(0.5528)
[2023-10-19 14:26:31,791][INFO] 	norm attack AUC: 1.0000(0.9953)
[2023-10-19 14:26:31,792][INFO] 	emb attack AUC: 0.8756(0.6053)
[2023-10-19 14:26:34,835][INFO] Epoch [2]: [780288/2598552] (30.03%)	Loss: 0.0610	AUC: 0.5583(0.5558)
[2023-10-19 14:26:34,835][INFO] 	norm attack AUC: 1.0000(0.9954)
[2023-10-19 14:26:34,835][INFO] 	emb attack AUC: 0.5523(0.6026)
[2023-10-19 14:26:37,660][INFO] Epoch [2]: [910336/2598552] (35.03%)	Loss: 0.0346	AUC: 0.7620(0.5587)
[2023-10-19 14:26:37,660][INFO] 	norm attack AUC: 1.0000(0.9961)
[2023-10-19 14:26:37,660][INFO] 	emb attack AUC: 0.6040(0.6051)
[2023-10-19 14:26:40,728][INFO] Epoch [2]: [1040384/2598552] (40.04%)	Loss: 0.0360	AUC: 0.5635(0.5601)
[2023-10-19 14:26:40,728][INFO] 	norm attack AUC: 1.0000(0.9966)
[2023-10-19 14:26:40,728][INFO] 	emb attack AUC: 0.5234(0.6054)
[2023-10-19 14:26:43,825][INFO] Epoch [2]: [1169408/2598552] (45.00%)	Loss: 0.0519	AUC: 0.4489(0.5633)
[2023-10-19 14:26:43,825][INFO] 	norm attack AUC: 1.0000(0.9969)
[2023-10-19 14:26:43,826][INFO] 	emb attack AUC: 0.5331(0.6054)
